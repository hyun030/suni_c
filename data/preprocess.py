# -*- coding: utf-8 -*-
from __future__ import annotations

import re
import pandas as pd
import streamlit as st
from bs4 import BeautifulSoup

_KRW_RE = re.compile(r'(krw|ì›|won)', re.IGNORECASE)

def _localname(qname: str) -> str:
    if not qname:
        return ''
    qname = qname.split('}')[-1]
    return qname.split(':')[-1].lower()

def _is_consolidated_context(ctx) -> bool | None:
    seg = ctx.find(lambda t: t.name and t.name.lower().endswith('segment'))
    if not seg:
        return None
    text = ' '.join([el.get_text(' ') for el in seg.find_all()])
    t = text.lower()
    if any(k in t for k in ['consolidated', 'ì—°ê²°', 'cfs', 'consolidatedmember', 'consolidatedgroupmember', 'dart:cfs']):
        return True
    if any(k in t for k in ['separate', 'ë³„ë„', 'separatemember', 'dart:separate']):
        return False
    return None


class FinancialDataProcessor:
    """ìˆ˜ë™ ì—…ë¡œë“œ XBRL â†’ ì—°ê²° ì†ìµê³„ì‚°ì„œì˜ ë¶„ê¸°(QTD) ê°’ìœ¼ë¡œ ì •ë¦¬"""

    # ì •í™• ë§¤í•‘(ë¡œì»¬ë„¤ì„ ìœ„ì£¼)
    CONCEPT_MAP = {
        'ë§¤ì¶œì•¡': [
            'ifrs-full:Revenue','revenue','sales','salesrevenue','operatingrevenue',
            'revenuefromcontractswithcustomers'
        ],
        'ë§¤ì¶œì›ê°€': ['costofsales','costofrevenue','costofgoodssold'],
        'ë§¤ì¶œì´ì´ìµ': ['grossprofit','grossincome'],
        'íŒë§¤ë¹„ì™€ê´€ë¦¬ë¹„': ['sellinggeneraladministrativeexpenses','sellingandadministrativeexpenses','sga'],
        'ì˜ì—…ì´ìµ': ['profitlossfromoperatingactivities','operatingincome','operatingprofit'],
        'ë‹¹ê¸°ìˆœì´ìµ': ['profitloss','netincome','netprofit'],
        # ë³´ì¡° í•­ëª©
        'ì˜ì—…ì™¸ìˆ˜ìµ': ['nonoperatingincome','otherincome','financialincome'],
        'ì˜ì—…ì™¸ë¹„ìš©': ['nonoperatingexpense','otherexpense','financialcost','interestexpense']
    }

    # ë°±ì—…ìš© ì •ê·œì‹
    CONCEPT_REGEX = {
        'ë§¤ì¶œì•¡': r'(revenue|sales)$',
        'ë§¤ì¶œì›ê°€': r'(costofsales|costofrevenue|costofgoods)$',
        'ë§¤ì¶œì´ì´ìµ': r'(grossprofit)$',
        'íŒë§¤ë¹„ì™€ê´€ë¦¬ë¹„': r'(selling.*administrative|sga$)',
        'ì˜ì—…ì´ìµ': r'(profitlossfromoperatingactivities|operatingprofit|operatingincome)$',
        'ë‹¹ê¸°ìˆœì´ìµ': r'(profitloss$|netincome$|netprofit$)',
    }

    def __init__(self, debug: bool=False):
        self.debug = debug

    # ---------------- I/O ----------------

    def load_file(self, uploaded_file):
        try:
            size = uploaded_file.size if hasattr(uploaded_file, 'size') else 0
            if size > 50*1024*1024:
                st.error("âŒ 50MB ì´í•˜ íŒŒì¼ë§Œ ì§€ì›í•©ë‹ˆë‹¤.")
                return None
            uploaded_file.seek(0)
            content = uploaded_file.read()
            xml = self._fast_decode(content)
            if not xml:
                st.error("âŒ íŒŒì¼ ì¸ì½”ë”©ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return None

            soup = self._safe_parse(xml)
            company = self._extract_company_name(soup, uploaded_file.name)

            facts = self._xbrl_to_facts(soup, company)
            if facts.empty:
                st.error("âŒ XBRL factë¥¼ ì½ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
                return None

            # report type: end ì›”ë¡œ íŒì •(3/6/9/12)
            rpt = self._guess_report_type_by_month(facts)
            if self.debug:
                with st.expander("ğŸ§­ XBRL Context ë¶„ë¥˜ ë””ë²„ê·¸"):
                    st.write(f"ReportType: {rpt}")
                    sample = facts[['context_id','period_type','start','end']].drop_duplicates().head(20)
                    st.dataframe(sample, use_container_width=True)

            # ì—°ê²°+KRW+ëŒ€ìƒ ë¶„ê¸° ìœˆë„ìš°ë¡œ ìŠ¬ë¼ì´ìŠ¤
            sliced = self._slice_to_quarter(facts, rpt)
            if sliced.empty:
                st.warning("âš ï¸ QTD ì»¨í…ìŠ¤íŠ¸ë¥¼ ëª» ì°¾ì•„ì„œ YTD ë³´ì •/ë°±ì—… ìŠ¤ìºë„ˆë¡œ ì‹œë„í•©ë‹ˆë‹¤.")
                sliced = self._slice_to_quarter_fallback(facts, rpt)

            items = self._facts_to_items(sliced)
            if not items:
                st.info("â„¹ï¸ facts ë§¤í•‘ ì‹¤íŒ¨ â†’ ë¬¸ì„œ íŒ¨í„´ ìŠ¤ìºë„ˆ ì‹œë„")
                items = self._backup_scan(soup)

            if not items:
                st.error("âŒ ì†ìµ í•­ëª©ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
                return None

            df = self._build_statement(items, company)
            return df

        except Exception as e:
            st.error(f"âŒ íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
            return None

    # ---------------- XML helpers ----------------

    def _safe_parse(self, content_str: str) -> BeautifulSoup:
        try:
            soup = BeautifulSoup(content_str, 'lxml-xml')
            if not soup.find():
                soup = BeautifulSoup(content_str, 'xml')
        except Exception:
            soup = BeautifulSoup(content_str, 'html.parser')
        return soup

    def _fast_decode(self, content: bytes) -> str | None:
        for enc in ['utf-8','utf-8-sig','cp949','euc-kr','iso-8859-1','ascii']:
            try:
                return content.decode(enc)
            except Exception:
                continue
        try:
            return content.decode('utf-8', errors='ignore')
        except Exception:
            return None

    def _extract_company_name(self, soup, filename):
        for t in ['EntityRegistrantName','CompanyName','ReportingEntityName','EntityName','CorporateName']:
            n = soup.find(t) or soup.find(lambda x: x.name and t.lower() in x.name.lower())
            if n and n.string and n.string.strip():
                return n.string.strip()
        name = (filename or '').split('.')[0].lower()
        mapping = {
            'sk':'SKì—ë„ˆì§€','skenergy':'SKì—ë„ˆì§€',
            'gs':'GSì¹¼í…ìŠ¤','gscaltex':'GSì¹¼í…ìŠ¤',
            'hd':'HDí˜„ëŒ€ì˜¤ì¼ë±…í¬','hyundai':'HDí˜„ëŒ€ì˜¤ì¼ë±…í¬','hdoil':'HDí˜„ëŒ€ì˜¤ì¼ë±…í¬',
            's-oil':'S-Oil','soil':'S-Oil','soilcorp':'S-Oil'
        }
        for k,v in mapping.items():
            if k in name: return v
        clean = re.sub(r'[^A-Za-zê°€-í£0-9\s]','', name) or "Unknown Company"
        return clean

    # ---------------- Facts building ----------------

    def _xbrl_to_facts(self, soup: BeautifulSoup, company: str) -> pd.DataFrame:
        # contexts
        ctx_rows = []
        for c in soup.find_all(lambda t: t.name and t.name.lower().endswith('context')):
            cid = c.get('id')
            if not cid: continue
            period = c.find(lambda t: t.name and t.name.lower().endswith('period'))
            start = end = inst = None
            ptype = 'instant'
            if period:
                s = period.find(lambda t: t.name and t.name.lower().endswith('startdate'))
                e = period.find(lambda t: t.name and t.name.lower().endswith('enddate'))
                i = period.find(lambda t: t.name and t.name.lower().endswith('instant'))
                if s and s.text: start = s.text.strip()
                if e and e.text: end   = e.text.strip()
                if i and i.text: inst  = i.text.strip()
                if start and end: ptype = 'duration'
            ctx_rows.append({
                'context_id': cid,
                'period_type': ptype,
                'start': start,
                'end': end or inst,
                'is_consolidated': _is_consolidated_context(c),
            })
        ctx_df = pd.DataFrame(ctx_rows)
        if ctx_df.empty:
            return pd.DataFrame()

        ctx_df['start'] = pd.to_datetime(ctx_df['start'], errors='coerce')
        ctx_df['end']   = pd.to_datetime(ctx_df['end'], errors='coerce')

        # units
        units = {}
        for u in soup.find_all(lambda t: t.name and t.name.lower().endswith('unit')):
            uid = u.get('id')
            if not uid: continue
            m = u.find(lambda t: t.name and t.name.lower().endswith('measure'))
            units[uid] = (m.text.strip() if m and m.text else None)

        # facts
        rows = []
        facts = soup.find_all(lambda t: (t.name and (t.get('contextRef') or t.get('contextref'))))
        for el in facts:
            text = (el.text or '').strip()
            if not text: continue
            try:
                val = float(re.sub(r'[^\d\.-]', '', text.replace('(', '-').replace(')', '')))
            except Exception:
                continue
            cref = el.get('contextRef') or el.get('contextref')
            uref = el.get('unitRef')    or el.get('unitref')
            rows.append({
                'íšŒì‚¬': company,
                'concept_qname': el.name,
                'concept_local': _localname(el.name),
                'value': val,
                'unit': units.get(uref, uref),
                'context_id': cref,
            })
        df = pd.DataFrame(rows)
        if df.empty:
            return df

        df = df.merge(ctx_df, on='context_id', how='left')
        return df

    def _guess_report_type_by_month(self, facts: pd.DataFrame) -> str:
        dur = facts[facts['period_type']=='duration'].copy()
        if dur['end'].notna().any():
            m = int(dur['end'].max().month)
            return {3:'Q1',6:'Q2',9:'Q3',12:'Q4'}.get(m,'Q3')
        return 'Q3'

    # ------------- Quarter slicing -------------

    def _slice_to_quarter(self, facts: pd.DataFrame, report_type: str) -> pd.DataFrame:
        f = facts.copy()

        # KRW & ì—°ê²° ìš°ì„  í•„í„°
        if 'unit' in f.columns:
            f = f[f['unit'].astype(str).str.contains(_KRW_RE, na=False)]
        if 'is_consolidated' in f.columns and f['is_consolidated'].notna().any():
            cfs = f['is_consolidated'] == True
            if cfs.any(): f = f[cfs]

        dur = f[f['period_type']=='duration'].copy()
        if dur.empty:
            return pd.DataFrame()

        # ëŒ€ìƒ ì—°ë„/ì›”
        end_max = dur['end'].max()
        year = end_max.year
        def pick(start_m, end_m):
            m = (dur['start'].dt.month==start_m) & (dur['end'].dt.month==end_m) & (dur['end'].dt.year==year)
            return dur[m]

        # QTD ìš°ì„ ìˆœìœ„
        if report_type=='Q1':
            qtd = pick(1,3)
            ytd = qtd  # Q1ì€ =YTD
            prev = pd.DataFrame()
        elif report_type=='Q2':
            qtd = pick(4,6)
            ytd = pick(1,6)
            prev = pick(1,3)
            if qtd.empty and not ytd.empty and not prev.empty:
                qtd = self._diff(ytd, prev)  # YTD - Q1
        elif report_type=='Q3':
            qtd = pick(7,9)
            ytd = pick(1,9)
            prev = pick(1,6)
            if qtd.empty and not ytd.empty and not prev.empty:
                qtd = self._diff(ytd, prev)  # YTD - H1
        else:  # Q4: ë¶„ê¸°ì¹˜(10~12) ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ ì—°ê°„-9ì›”
            qtd = pick(10,12)
            ytd = pick(1,12)
            prev = pick(1,9)
            if qtd.empty and not ytd.empty and not prev.empty:
                qtd = self._diff(ytd, prev)

        return qtd

    def _slice_to_quarter_fallback(self, facts: pd.DataFrame, report_type: str) -> pd.DataFrame:
        """ì»¨í…ìŠ¤íŠ¸ id ë¬¸ìì—´ì—ì„œ 7-9/4-6 ë“± íŒ¨í„´ì´ ë³´ì¼ ë•Œ ë³´ì¡°ë¡œ ì„ íƒ"""
        dur = facts[(facts['period_type']=='duration')].copy()
        if dur.empty:
            return dur
        pat = None
        if report_type=='Q3':
            pat = re.compile(r'(7.?01|07.?01).*(9.?30|09.?30)')
        elif report_type=='Q2':
            pat = re.compile(r'(4.?01|04.?01).*(6.?30|06.?30)')
        elif report_type=='Q1':
            pat = re.compile(r'(1.?01|01.?01).*(3.?31|03.?31)')
        else:
            pat = re.compile(r'(10.?01).*(12.?31)')
        if pat:
            mask = dur['context_id'].astype(str).str.contains(pat, regex=True, na=False)
            cand = dur[mask]
            return cand
        return pd.DataFrame()

    def _diff(self, ytd: pd.DataFrame, prev: pd.DataFrame) -> pd.DataFrame:
        """ë™ì¼ concept/local ê¸°ì¤€ìœ¼ë¡œ ytd - prev ì°¨ê°"""
        y = ytd[['concept_local','concept_qname','value','unit','context_id','start','end']].copy()
        p = prev[['concept_local','value']].rename(columns={'value':'prev'}).copy()
        out = y.merge(p, on='concept_local', how='left')
        out['value'] = out['value'] - out['prev'].fillna(0)
        # prev ì§€ìš°ê³  ìƒˆë¡œìš´ ê°€ìƒ context_id ë¶€ì—¬
        out = out.drop(columns=['prev'])
        out['context_id'] = out['context_id'].astype(str) + '_QTD'
        return out

    # ------------- Mapping to items -------------

    def _facts_to_items(self, df: pd.DataFrame) -> dict:
        if df is None or df.empty:
            return {}
        items = {}

        # 1) ì •í™• ë§¤í•‘(ì—¬ëŸ¬ í›„ë³´ ì¤‘ ì ˆëŒ“ê°’ í° ê°’)
        for std, cands in self.CONCEPT_MAP.items():
            vals = []
            for q in cands:
                key = _localname(q)
                vals.append(df[df['concept_local']==key]['value'])
            s = pd.concat(vals) if vals else pd.Series(dtype=float)
            if not s.empty:
                v = s.reindex(s.abs().sort_values(ascending=False).index).iloc[0]
                items[std] = float(v)

        # 2) ì •ê·œì‹ ë³´ê°•
        for std, rx in self.CONCEPT_REGEX.items():
            if std in items: continue
            m = df['concept_local'].str.contains(rx, regex=True, na=False)
            if m.any():
                s = df.loc[m, 'value']
                v = s.reindex(s.abs().sort_values(ascending=False).index).iloc[0]
                items[std] = float(v)

        # íŒŒìƒ
        if 'ë§¤ì¶œì´ì´ìµ' not in items and 'ë§¤ì¶œì•¡' in items and 'ë§¤ì¶œì›ê°€' in items:
            items['ë§¤ì¶œì´ì´ìµ'] = items['ë§¤ì¶œì•¡'] - items['ë§¤ì¶œì›ê°€']
        if 'ì˜ì—…ì´ìµ' not in items and 'ë§¤ì¶œì´ì´ìµ' in items and 'íŒë§¤ë¹„ì™€ê´€ë¦¬ë¹„' in items:
            items['ì˜ì—…ì´ìµ'] = items['ë§¤ì¶œì´ì´ìµ'] - items['íŒë§¤ë¹„ì™€ê´€ë¦¬ë¹„']

        return items

    # ------------- Backup scanner -------------

    def _backup_scan(self, soup: BeautifulSoup) -> dict:
        # ìˆ«ì í¬í•¨ íƒœê·¸ë“¤ í›‘ì–´ì„œ ë„“ì€ íŒ¨í„´ ë§¤ì¹­
        items, processed = {}, 0
        numeric = [t for t in soup.find_all() if t.string and re.search(r'\d', t.string)]
        for tag in numeric:
            txt = tag.string.strip()
            try:
                num = float(re.sub(r'[^\d\.-]', '', txt.replace('(', '-').replace(')', '')))
            except Exception:
                continue
            if abs(num) < 10000:  # ë…¸ì´ì¦ˆ ì»·
                continue
            # íƒœê·¸/ë¶€ëª¨/ì†ì„± í•©ì„±
            parts = [tag.name.lower() if tag.name else '']
            if tag.attrs:
                parts.extend([str(v).lower() for v in tag.attrs.values()])
            if tag.parent and tag.parent.name:
                parts.append(tag.parent.name.lower())
            info = ' '.join(parts)
            for rx, std in {
                r'(revenue|sales)(?!.*cost)': 'ë§¤ì¶œì•¡',
                r'(cost.*(sales|goods))|ë§¤ì¶œì›ê°€|ì›ê°€': 'ë§¤ì¶œì›ê°€',
                r'(gross.*profit|ë§¤ì¶œì´ì´ìµ)': 'ë§¤ì¶œì´ì´ìµ',
                r'(selling.*administrative|íŒê´€ë¹„|íŒë§¤ë¹„.*ê´€ë¦¬ë¹„)': 'íŒë§¤ë¹„ì™€ê´€ë¦¬ë¹„',
                r'(operating.*(income|profit)|ì˜ì—…ì´ìµ)': 'ì˜ì—…ì´ìµ',
                r'(profitloss$|netincome$|netprofit$|ë‹¹ê¸°ìˆœì´ìµ)': 'ë‹¹ê¸°ìˆœì´ìµ'
            }.items():
                if re.search(rx, info, re.IGNORECASE):
                    if std not in items or abs(num) > abs(items[std]):
                        items[std] = num
        return items

    # ------------- Statement / ratios / merge -------------

    def _build_statement(self, data: dict, company: str) -> pd.DataFrame:
        order = ['ë§¤ì¶œì•¡','ë§¤ì¶œì›ê°€','ë§¤ì¶œì´ì´ìµ','íŒë§¤ë¹„ì™€ê´€ë¦¬ë¹„','ì˜ì—…ì´ìµ','ì˜ì—…ì™¸ìˆ˜ìµ','ì˜ì—…ì™¸ë¹„ìš©','ë‹¹ê¸°ìˆœì´ìµ']
        rows = []
        for k in order:
            if k in data:
                rows.append({'êµ¬ë¶„': k, company: self._fmt_amt(data[k]), f'{company}_ì›ì‹œê°’': data[k]})
        # ratios
        sales = data.get('ë§¤ì¶œì•¡', 0)
        if sales:
            def r(name, num): rows.append({'êµ¬ë¶„': name, company: f"{(num/sales)*100:.2f}%", f'{company}_ì›ì‹œê°’': (num/sales)*100})
            if 'ì˜ì—…ì´ìµ' in data: r('ì˜ì—…ì´ìµë¥ (%)', data['ì˜ì—…ì´ìµ'])
            if 'ë§¤ì¶œì´ì´ìµ' in data: r('ë§¤ì¶œì´ì´ìµë¥ (%)', data['ë§¤ì¶œì´ì´ìµ'])
            if 'ë‹¹ê¸°ìˆœì´ìµ' in data: r('ìˆœì´ìµë¥ (%)', data['ë‹¹ê¸°ìˆœì´ìµ'])
            if 'ë§¤ì¶œì›ê°€' in data: r('ë§¤ì¶œì›ê°€ìœ¨(%)', data['ë§¤ì¶œì›ê°€'])
            if 'íŒë§¤ë¹„ì™€ê´€ë¦¬ë¹„' in data: r('íŒê´€ë¹„ìœ¨(%)', data['íŒë§¤ë¹„ì™€ê´€ë¦¬ë¹„'])
        return pd.DataFrame(rows)

    def _fmt_amt(self, v: float) -> str:
        if v == 0: return "0ì›"
        sign = "â–¼ " if v < 0 else ""
        a = abs(v)
        if a >= 1_000_000_000_000: return f"{sign}{v/1_000_000_000_000:.1f}ì¡°ì›"
        if a >= 100_000_000:        return f"{sign}{v/100_000_000:.0f}ì–µì›"
        if a >= 10_000:             return f"{sign}{v/10_000:.0f}ë§Œì›"
        return f"{sign}{v:,.0f}ì›"

    def merge_company_data(self, dataframes: list[pd.DataFrame]):
        if not dataframes: return pd.DataFrame()
        if len(dataframes) == 1: return dataframes[0]
        merged = dataframes[0].copy()
        for df in dataframes[1:]:
            try:
                cols = [c for c in df.columns if c != 'êµ¬ë¶„' and not c.endswith('_ì›ì‹œê°’')]
                for c in cols:
                    merged = merged.set_index('êµ¬ë¶„').join(df.set_index('êµ¬ë¶„')[c], how='outer').reset_index()
            except Exception as e:
                st.warning(f"âš ï¸ ë³‘í•© ì¤‘ ì˜¤ë¥˜: {e}")
        return merged.fillna("-")

# --- backward compatibility shim ---
SKFinancialDataProcessor = FinancialDataProcessor
__all__ = ["FinancialDataProcessor", "SKFinancialDataProcessor"]
